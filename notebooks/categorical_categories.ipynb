{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most highly categorised data in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T14:41:17.244647Z",
     "start_time": "2023-05-17T14:41:17.241419Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T14:41:17.382785Z",
     "start_time": "2023-05-17T14:41:17.249878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File imagenet_classes.txt already exists\n"
     ]
    }
   ],
   "source": [
    "# Download ImageNet labels\n",
    "\n",
    "! if [ -f \"imagenet_classes.txt\" ]; then echo \"File imagenet_classes.txt already exists\"; else wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt 2> /dev/null; fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T14:41:17.383418Z",
     "start_time": "2023-05-17T14:41:17.369820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T14:42:21.013786Z",
     "start_time": "2023-05-17T14:41:17.383290Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Load the softmax encodings of the data\n",
    "\n",
    "from sisap2023.utils.mirflickr import load_encodings\n",
    "\n",
    "smData = load_encodings(Path('/Volumes/Data/mf_resnet50_softmax'))\n",
    "\n",
    "# Load the data\n",
    "\n",
    "allData = load_encodings(Path(\"/Volumes/Data/mf_resnet50\")) # load resnet 50 encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 100 results\n",
      "9 124 ostrich 124\n",
      "12 143 house finch 143\n",
      "15 110 robin 110\n",
      "31 106 tree frog 106\n",
      "131 109 little blue heron 109\n",
      "145 125 king penguin 125\n",
      "146 147 albatross 147\n",
      "148 121 killer whale 121\n",
      "150 122 sea lion 122\n",
      "151 134 Chihuahua 134\n",
      "207 124 golden retriever 124\n",
      "292 144 tiger 144\n",
      "310 132 ant 132\n",
      "315 142 mantis 142\n",
      "320 120 damselfly 120\n",
      "324 144 cabbage butterfly 144\n",
      "327 102 starfish 102\n",
      "348 133 ram 133\n",
      "354 136 Arabian camel 136\n",
      "366 136 gorilla 136\n",
      "401 137 accordion 137\n",
      "402 154 acoustic guitar 154\n",
      "406 122 altar 122\n",
      "424 135 barbershop 135\n",
      "433 101 bathing cap 101\n",
      "441 157 beer glass 157\n",
      "442 111 bell cote 111\n",
      "447 105 binoculars 105\n",
      "448 109 birdhouse 109\n",
      "452 165 bonnet 165\n",
      "455 165 bottlecap 165\n",
      "457 120 bow tie 120\n",
      "460 132 breakwater 132\n",
      "466 114 bullet train 114\n",
      "475 174 car mirror 174\n",
      "476 159 carousel 159\n",
      "488 119 chain 119\n",
      "510 103 container ship 103\n",
      "515 113 cowboy hat 113\n",
      "536 183 dock 183\n",
      "546 138 electric guitar 138\n",
      "555 150 fire engine 150\n",
      "568 159 fur coat 159\n",
      "603 162 horse cart 162\n",
      "605 172 iPod 172\n",
      "608 160 jean 160\n",
      "615 102 knee pad 102\n",
      "616 134 knot 134\n",
      "629 119 lipstick 119\n",
      "637 110 mailbox 110\n",
      "640 118 manhole cover 118\n",
      "644 121 matchstick 121\n",
      "655 126 miniskirt 126\n",
      "661 118 Model T 118\n",
      "671 145 mountain bike 145\n",
      "679 157 necklace 157\n",
      "687 114 organ 114\n",
      "695 169 padlock 169\n",
      "701 154 parachute 154\n",
      "705 130 passenger car 130\n",
      "708 175 pedestal 175\n",
      "715 120 pickelhaube 120\n",
      "716 155 picket fence 155\n",
      "724 104 pirate 104\n",
      "733 117 pole 117\n",
      "734 111 police van 111\n",
      "736 147 pool table 147\n",
      "738 129 pot 129\n",
      "746 101 puck 101\n",
      "770 148 running shoe 148\n",
      "781 119 scoreboard 119\n",
      "791 125 shopping cart 125\n",
      "795 102 ski 102\n",
      "806 152 sock 152\n",
      "807 105 solar dish 105\n",
      "817 132 sports car 132\n",
      "842 123 swimming trunks 123\n",
      "843 173 swing 173\n",
      "847 102 tank 102\n",
      "853 182 thatch 182\n",
      "865 122 toyshop 122\n",
      "872 108 tripod 108\n",
      "890 132 volleyball 132\n",
      "900 124 water tower 124\n",
      "904 106 window screen 106\n",
      "912 169 worm fence 169\n",
      "918 157 crossword puzzle 157\n",
      "937 110 broccoli 110\n",
      "945 137 bell pepper 137\n",
      "950 143 orange 143\n",
      "957 138 pomegranate 138\n",
      "960 113 chocolate sauce 113\n",
      "963 167 pizza 167\n",
      "967 160 espresso 160\n",
      "972 120 cliff 120\n",
      "974 131 geyser 131\n",
      "975 180 lakeside 180\n",
      "976 129 promontory 129\n",
      "981 153 ballplayer 153\n",
      "982 162 groom 162\n"
     ]
    }
   ],
   "source": [
    "from sisap2023.utils.count_cats import count_number_in_cat_gt_thresh, find_cats_with_count_more_than_less_than\n",
    "\n",
    "threshold = 0.90\n",
    "\n",
    "top_categories,counts = find_cats_with_count_more_than_less_than(100,184,smData,threshold)\n",
    "\n",
    "print( f\"found {top_categories.size} results\")\n",
    "for i in range(top_categories.size):\n",
    "    print( top_categories[i], counts[i], categories[top_categories[i]], count_number_in_cat_gt_thresh(top_categories[i],threshold,smData) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sisap2023.utils.count_cats import get_best_cat_index\n",
    "from typing import List\n",
    "\n",
    "def get_nth_categorical_query(categories: np.array, sm_data: np.array, n: int) -> List[int]:\n",
    "    \"\"\"Return the nth categorical query in each of the supplied categories\"\"\"\n",
    "    results = []\n",
    "    for cat_required in categories:\n",
    "        cats = get_best_cat_index(cat_required, sm_data)  # all the data in most categorical order (not efficient!)\n",
    "        results.append(cats[n])  # just get the nth categorical one\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = get_nth_categorical_query(top_categories[0:100],smData,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num queries = 100\n",
      "130995\n",
      "682918\n",
      "770223\n",
      "903223\n",
      "642214\n",
      "984174\n",
      "336954\n",
      "681592\n",
      "191942\n",
      "638298\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num queries = {len(queries)}\")\n",
    "for i in range(10):\n",
    "    print( queries[i] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
